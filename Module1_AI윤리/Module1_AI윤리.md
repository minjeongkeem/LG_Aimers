#  데이터 처리 및 수집에서 윤리 이슈

## 데이터 해석

- 상관관계는 인과관계와 다르다

## 데이터처리 및 정제

- Error bar가 없는 그래프는 주의 

- 적합한 통계 테스트

- 아웃라이어 제거

- 데이터 표준화

- 충분한 EDA 

## 데이터의 양

- underfitting: 데이터 양이 너무 작을 때 주로 발생

- overfitting: 데이터가 조금만 달라져도 쓸 수 없음

- training데이터와 testing데이터가 달라야함

## black box algorithm

- Decisition tree: '이런 경로로 결과값이 나왔다' > 다소 명확함
  
- 다수의 AI 모델은 그 안에 복잡한 파라미터 값으로 결과가 나오며 해석이 어려움 > black box

- (ex) 설명력이 중요한 AI 예시: 탈세범 검출
 
- 성능은 조금 떨어지지만, 설명력을 높여주는 알고리즘 사용 > 현실 세계에서는 성능 뿐만 아니라 설명력이 중요함

- (ex) CV 기술로 알고리즘 내부를 보여주는 결과물: 사후설명력, post-hoc explainability

- one pixel attack: 픽셀 하나만 바뀐다고 결과물이 바뀜 (공격에 취약)

## Handling Web Data

- 정보의 대표성: 많이 언급되는 토픽이 꼭 중요한 토픽은 아니다. > spiral of silence (편향 현상)

- 오정보 주의 > 인포데믹 현상 주의 (사실과 오정보가 너무 많아 구분이 어려운 정보 과부화 현상)

- 사용자의 불편은 무엇인가? 

- 꼭 필요한 정보만 요청하고 있는지? 

- 잊혀질 기회 (the right to be forgotten)

## AI 윤리

- GDPR (EU 데이터 규제)

## AI 신뢰도

- 인공지능 알고리즘으로 인한 부작용

- (ex) COMPAS: 미국에서 판결시 재범률을 예측하여 보여줌

## 데이터 사이언스 Tip

- 이중 데이터 결합
- (ex) 서울 버스 수요: 없는 노선에 해서는 이동통신 데이터와 결합하여 예측
